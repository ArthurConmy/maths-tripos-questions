---
course: Statistics
course_year: IB
question_number: 75
tags:
- IB
- '2010'
- Statistics
title: 'Paper 3, Section II, E '
year: 2010
---



Let $X_{1}, \ldots, X_{n}$ be independent $\operatorname{Exp}(\theta)$ random variables with unknown parameter $\theta$. Find the maximum likelihood estimator $\hat{\theta}$ of $\theta$, and state the distribution of $n / \hat{\theta}$. Show that $\theta / \hat{\theta}$ has the $\Gamma(n, n)$ distribution. Find the $100(1-\alpha) \%$ confidence interval for $\theta$ of the form $[0, C \hat{\theta}]$ for a constant $C>0$ depending on $\alpha$.

Now, taking a Bayesian point of view, suppose your prior distribution for the parameter $\theta$ is $\Gamma(k, \lambda)$. Show that your Bayesian point estimator $\hat{\theta}_{B}$ of $\theta$ for the loss function $L(\theta, a)=(\theta-a)^{2}$ is given by

$$\hat{\theta}_{B}=\frac{n+k}{\lambda+\sum_{i} X_{i}} .$$

Find a constant $C_{B}>0$ depending on $\alpha$ such that the posterior probability that $\theta \leqslant C_{B} \hat{\theta}_{B}$ is equal to $1-\alpha$.

[The density of the $\Gamma(k, \lambda)$ distribution is $f(x ; k, \lambda)=\lambda^{k} x^{k-1} e^{-\lambda x} / \Gamma(k)$, for $\left.x>0 .\right]$