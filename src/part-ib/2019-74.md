---
course: Statistics
course_year: IB
question_number: 74
tags:
- IB
- '2019'
- Statistics
title: 'Paper 4, Section II, 19H '
year: 2019
---



Consider the linear model

$$Y_{i}=\beta x_{i}+\epsilon_{i} \quad \text { for } \quad i=1, \ldots, n$$

where $x_{1}, \ldots, x_{n}$ are known and $\epsilon_{1}, \ldots, \epsilon_{n}$ are i.i.d. $N\left(0, \sigma^{2}\right)$. We assume that the parameters $\beta$ and $\sigma^{2}$ are unknown.

(a) Find the MLE $\widehat{\beta}$ of $\beta$. Explain why $\widehat{\beta}$ is the same as the least squares estimator of $\beta$.

(b) State and prove the Gauss-Markov theorem for this model.

(c) For each value of $\theta \in \mathbb{R}$ with $\theta \neq 0$, determine the unbiased linear estimator $\tilde{\beta}$ of $\beta$ which minimizes

$$\mathbb{E}_{\beta, \sigma^{2}}[\exp (\theta(\tilde{\beta}-\beta))]$$