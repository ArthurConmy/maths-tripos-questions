---
course: Statistics
course_year: IB
question_number: 67
tags:
- IB
- '2007'
- Statistics
title: '1.II.18C '
year: 2007
---


Let $X_{1}, \ldots, X_{n}$ be independent, identically distributed random variables with

$$\mathbb{P}\left(X_{i}=1\right)=\theta=1-\mathbb{P}\left(X_{i}=0\right)$$

where $\theta$ is an unknown parameter, $0<\theta<1$, and $n \geqslant 2$. It is desired to estimate the quantity $\phi=\theta(1-\theta)=n \operatorname{Var}\left(\left(X_{1}+\cdots+X_{n}\right) / n\right)$.

(i) Find the maximum-likelihood estimate, $\hat{\phi}$, of $\phi$.

(ii) Show that $\hat{\phi}_{1}=X_{1}\left(1-X_{2}\right)$ is an unbiased estimate of $\phi$ and hence, or otherwise, obtain an unbiased estimate of $\phi$ which has smaller variance than $\hat{\phi}_{1}$ and which is a function of $\hat{\phi}$.

(iii) Now suppose that a Bayesian approach is adopted and that the prior distribution for $\theta, \pi(\theta)$, is taken to be the uniform distribution on $(0,1)$. Compute the Bayes point estimate of $\phi$ when the loss function is $L(\phi, a)=(\phi-a)^{2}$.

[You may use that fact that when $r, s$ are non-negative integers,

$$\left.\int_{0}^{1} x^{r}(1-x)^{s} d x=r ! s ! /(r+s+1) !\right]$$