---
course: Vector Calculus
course_year: IA
question_number: 36
title: Paper 3, Section I, B Vector Calculus
year: 2019
---



Apply the divergence theorem to the vector field $\mathbf{u}(\mathbf{x})=\mathbf{a} \phi(\mathbf{x})$ where $\mathbf{a}$ is an arbitrary constant vector and $\phi$ is a scalar field, to show that

$$\int_{V} \nabla \phi d V=\int_{S} \phi d \mathbf{S}$$

where $V$ is a volume bounded by the surface $S$ and $d \mathbf{S}$ is the outward pointing surface element.

Verify that this result holds when $\phi=x+y$ and $V$ is the spherical volume $x^{2}+$ $y^{2}+z^{2} \leqslant a^{2}$. [You may use the result that $d \mathbf{S}=a^{2} \sin \theta d \theta d \phi(\sin \theta \cos \phi, \sin \theta \sin \phi, \cos \theta)$, where $\theta$ and $\phi$ are the usual angular coordinates in spherical polars and the components of $d \mathbf{S}$ are with respect to standard Cartesian axes.]