---
course: Statistics
course_year: IB
question_number: 72
tags:
- IB
- '2014'
- Statistics
title: 'Paper 4, Section II, H '
year: 2014
---



Consider a linear model

$$\mathbf{Y}=X \boldsymbol{\beta}+\varepsilon$$

where $X$ is a known $n \times p$ matrix, $\boldsymbol{\beta}$ is a $p \times 1(p<n)$ vector of unknown parameters and $\varepsilon$ is an $n \times 1$ vector of independent $N\left(0, \sigma^{2}\right)$ random variables with $\sigma^{2}$ unknown. Assume that $X$ has full rank $p$. Find the least squares estimator $\hat{\boldsymbol{\beta}}$ of $\boldsymbol{\beta}$ and derive its distribution. Define the residual sum of squares $R S S$ and write down an unbiased estimator $\hat{\sigma}^{2}$ of $\sigma^{2}$.

Suppose that $V_{i}=a+b u_{i}+\delta_{i}$ and $Z_{i}=c+d w_{i}+\eta_{i}$, for $i=1, \ldots, m$, where $u_{i}$ and $w_{i}$ are known with $\sum_{i=1}^{m} u_{i}=\sum_{i=1}^{m} w_{i}=0$, and $\delta_{1}, \ldots, \delta_{m}, \eta_{1}, \ldots, \eta_{m}$ are independent $N\left(0, \sigma^{2}\right)$ random variables. Assume that at least two of the $u_{i}$ are distinct and at least two of the $w_{i}$ are distinct. Show that $\mathbf{Y}=\left(V_{1}, \ldots, V_{m}, Z_{1}, \ldots, Z_{m}\right)^{T}$ (where $T$ denotes transpose) may be written as in ( $\dagger$ ) and identify $X$ and $\boldsymbol{\beta}$. Find $\hat{\boldsymbol{\beta}}$ in terms of the $V_{i}, Z_{i}$, $u_{i}$ and $w_{i}$. Find the distribution of $\hat{b}-\hat{d}$ and derive a $95 \%$ confidence interval for $b-d$.

[Hint: You may assume that $\frac{R S S}{\sigma^{2}}$ has a $\chi_{n-p}^{2}$ distribution, and that $\hat{\beta}$ and the residual sum of squares are independent. Properties of $\chi^{2}$ distributions may be used without proof.]