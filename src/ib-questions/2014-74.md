---
course: Statistics
course_year: IB
question_number: 74
tags:
- IB
- '2014'
- Statistics
title: 'Paper 3, Section II, H '
year: 2014
---



Suppose that $X_{1}, \ldots, X_{n}$ are independent identically distributed random variables with

$$\mathbb{P}\left(X_{i}=x\right)=\left(\begin{array}{c}
k \\
x
\end{array}\right) \theta^{x}(1-\theta)^{k-x}, \quad x=0, \ldots, k$$

where $k$ is known and $\theta(0<\theta<1)$ is an unknown parameter. Find the maximum likelihood estimator $\hat{\theta}$ of $\theta$.

Statistician 1 has prior density for $\theta$ given by $\pi_{1}(\theta)=\alpha \theta^{\alpha-1}, 0<\theta<1$, where $\alpha>1$. Find the posterior distribution for $\theta$ after observing data $X_{1}=x_{1}, \ldots, X_{n}=x_{n}$. Write down the posterior mean $\hat{\theta}_{1}^{(B)}$, and show that

$$\hat{\theta}_{1}^{(B)}=c \hat{\theta}+(1-c) \tilde{\theta}_{1}$$

where $\tilde{\theta}_{1}$ depends only on the prior distribution and $c$ is a constant in $(0,1)$ that is to be specified.

Statistician 2 has prior density for $\theta$ given by $\pi_{2}(\theta)=\alpha(1-\theta)^{\alpha-1}, 0<\theta<1$. Briefly describe the prior beliefs that the two statisticians hold about $\theta$. Find the posterior mean $\hat{\theta}_{2}^{(B)}$ and show that $\hat{\theta}_{2}^{(B)}<\hat{\theta}_{1}^{(B)}$.

Suppose that $\alpha$ increases (but $n, k$ and the $x_{i}$ remain unchanged). How do the prior beliefs of the two statisticians change? How does $c$ vary? Explain briefly what happens to $\hat{\theta}_{1}^{(B)}$ and $\hat{\theta}_{2}^{(B)}$.

[Hint: The Beta $(\alpha, \beta)(\alpha>0, \beta>0)$ distribution has density

$$f(x)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha) \Gamma(\beta)} x^{\alpha-1}(1-x)^{\beta-1}, \quad 0<x<1$$

with expectation $\frac{\alpha}{\alpha+\beta}$ and variance $\frac{\alpha \beta}{(\alpha+\beta+1)(\alpha+\beta)^{2}}$. Here, $\Gamma(\alpha)=\int_{0}^{\infty} x^{\alpha-1} e^{-x} d x, \alpha>0$, is the Gamma function.]