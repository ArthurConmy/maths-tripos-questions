---
course: Statistics
course_year: IB
question_number: 74
tags:
- IB
- '2010'
- Statistics
title: 'Paper 1, Section II, E '
year: 2010
---



Consider the the linear regression model

$$Y_{i}=\beta x_{i}+\epsilon_{i},$$

where the numbers $x_{1}, \ldots, x_{n}$ are known, the independent random variables $\epsilon_{1}, \ldots, \epsilon_{n}$ have the $N\left(0, \sigma^{2}\right)$ distribution, and the parameters $\beta$ and $\sigma^{2}$ are unknown. Find the maximum likelihood estimator for $\beta$.

State and prove the Gauss-Markov theorem in the context of this model.

Write down the distribution of an arbitrary linear estimator for $\beta$. Hence show that there exists a linear, unbiased estimator $\widehat{\beta}$ for $\beta$ such that

$$\mathbb{E}_{\beta, \sigma^{2}}\left[(\widehat{\beta}-\beta)^{4}\right] \leqslant \mathbb{E}_{\beta, \sigma^{2}}\left[(\widetilde{\beta}-\beta)^{4}\right]$$

for all linear, unbiased estimators $\widetilde{\beta}$.

[Hint: If $Z \sim N\left(a, b^{2}\right)$ then $\left.\mathbb{E}\left[(Z-a)^{4}\right]=3 b^{4} .\right]$