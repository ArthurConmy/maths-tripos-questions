---
course: Markov Chains
course_year: IB
question_number: 75
tags:
- IB
- '2006'
- Markov Chains
title: '1.II.19C '
year: 2006
---


Explain what is meant by a stopping time of a Markov chain $\left(X_{n}\right)_{n \geq 0}$. State the strong Markov property.

Show that, for any state $i$, the probability, starting from $i$, that $\left(X_{n}\right)_{n \geq 0}$ makes infinitely many visits to $i$ can take only the values 0 or 1 .

Show moreover that, if

$$\sum_{n=0}^{\infty} \mathbb{P}_{i}\left(X_{n}=i\right)=\infty$$

then $\left(X_{n}\right)_{n \geq 0}$ makes infinitely many visits to $i$ with probability $1 .$