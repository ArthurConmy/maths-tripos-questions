---
course: Statistics
course_year: IB
question_number: 76
tags:
- IB
- '2011'
- Statistics
title: 'Paper 3, Section II, H '
year: 2011
---



Consider the general linear model

$$Y=X \beta+\epsilon$$

where $X$ is a known $n \times p$ matrix, $\beta$ is an unknown $p \times 1$ vector of parameters, and $\epsilon$ is an $n \times 1$ vector of independent $N\left(0, \sigma^{2}\right)$ random variables with unknown variance $\sigma^{2}$. Assume the $p \times p$ matrix $X^{T} X$ is invertible.

(i) Derive the least squares estimator $\widehat{\beta}$ of $\beta$.

(ii) Derive the distribution of $\widehat{\beta}$. Is $\widehat{\beta}$ an unbiased estimator of $\beta$ ?

(iii) Show that $\frac{1}{\sigma^{2}}\|Y-X \widehat{\beta}\|^{2}$ has the $\chi^{2}$ distribution with $k$ degrees of freedom, where $k$ is to be determined.

(iv) Let $\tilde{\beta}$ be an unbiased estimator of $\beta$ of the form $\tilde{\beta}=C Y$ for some $p \times n$ matrix $C$. By considering the matrix $\mathbb{E}\left[(\widehat{\beta}-\widetilde{\beta})(\widehat{\beta}-\beta)^{T}\right]$ or otherwise, show that $\widehat{\beta}$ and $\widehat{\beta}-\widetilde{\beta}$ are independent.

[You may use standard facts about the multivariate normal distribution as well as results from linear algebra, including the fact that $I-X\left(X^{T} X\right)^{-1} X^{T}$ is a projection matrix of rank $n-p$, as long as they are carefully stated.]