---
course: Principles of Statistics
course_year: II
question_number: 121
tags:
- II
- '2014'
- Principles of Statistics
title: 'Paper 2, Section II, J '
year: 2014
---



In a general decision problem, define the concepts of a Bayes rule and of admissibility. Show that a unique Bayes rule is admissible.

Consider i.i.d. observations $X_{1}, \ldots, X_{n}$ from a $\operatorname{Poisson}(\theta), \theta \in \Theta=(0, \infty)$, model. Can the maximum likelihood estimator $\hat{\theta}_{M L E}$ of $\theta$ be a Bayes rule for estimating $\theta$ in quadratic risk for any prior distribution on $\theta$ that has a continuous probability density on $(0, \infty) ?$ Justify your answer.

Now model the $X_{i}$ as i.i.d. copies of $X \mid \theta \sim \operatorname{Poisson}(\theta)$, where $\theta$ is drawn from a prior that is a Gamma distribution with parameters $\alpha>0$ and $\lambda>0$ (given below). Show that the posterior distribution of $\theta \mid X_{1}, \ldots, X_{n}$ is a Gamma distribution and find its parameters. Find the Bayes rule $\hat{\theta}_{B A Y E S}$ for estimating $\theta$ in quadratic risk for this prior. [The Gamma probability density function with parameters $\alpha>0, \lambda>0$ is given by

$$f(\theta)=\frac{\lambda^{\alpha} \theta^{\alpha-1} e^{-\lambda \theta}}{\Gamma(\alpha)}, \quad \theta>0$$

where $\Gamma(\alpha)$ is the usual Gamma function.]

Finally assume that the $X_{i}$ have actually been generated from a fixed Poisson $\left(\theta_{0}\right)$ distribution, where $\theta_{0}>0$. Show that $\sqrt{n}\left(\hat{\theta}_{B A Y E S}-\hat{\theta}_{M L E}\right)$ converges to zero in probability and deduce the asymptotic distribution of $\sqrt{n}\left(\hat{\theta}_{B A Y E S}-\theta_{0}\right)$ under the joint law $P_{\theta_{0}}^{\mathbb{N}}$ of the random variables $X_{1}, X_{2}, \ldots$. [You may use standard results from lectures without proof provided they are clearly stated.]