---
course: Computational Statistics and Statistical Modelling
course_year: II
question_number: 14
tags:
- II
- '2001'
- Computational Statistics and Statistical Modelling
title: 'A1.13 '
year: 2001
---


(i) Assume that the $n$-dimensional observation vector $Y$ may be written as

$$Y=X \beta+\epsilon$$

where $X$ is a given $n \times p$ matrix of $\operatorname{rank} p, \beta$ is an unknown vector, and

$$\epsilon \sim N_{n}\left(0, \sigma^{2} I\right)$$

Let $Q(\beta)=(Y-X \beta)^{T}(Y-X \beta)$. Find $\widehat{\beta}$, the least-squares estimator of $\beta$, and show that

$$Q(\widehat{\beta})=Y^{T}(I-H) Y$$

where $H$ is a matrix that you should define.

(ii) Show that $\sum_{i} H_{i i}=p$. Show further for the special case of

$$Y_{i}=\beta_{1}+\beta_{2} x_{i}+\beta_{3} z_{i}+\epsilon_{i}, \quad 1 \leqslant i \leqslant n$$

where $\Sigma x_{i}=0, \Sigma z_{i}=0$, that

$$H=\frac{1}{n} \mathbf{1 1}{ }^{T}+a x x^{T}+b\left(x z^{T}+z x^{T}\right)+c z z^{T} ;$$

here, $\mathbf{1}$ is a vector of which every element is one, and $a, b, c$, are constants that you should derive.

Hence show that, if $\widehat{Y}=X \widehat{\beta}$ is the vector of fitted values, then

$$\frac{1}{\sigma^{2}} \operatorname{var}\left(\widehat{Y}_{i}\right)=\frac{1}{n}+a x_{i}^{2}+2 b x_{i} z_{i}+c z_{i}^{2}, \quad 1 \leqslant i \leqslant n .$$