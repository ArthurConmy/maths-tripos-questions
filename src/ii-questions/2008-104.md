---
course: Principles of Statistics
course_year: II
question_number: 104
tags:
- II
- '2008'
- Principles of Statistics
title: '2.II.27I '
year: 2008
---


Under hypothesis $H_{i}(i=0,1)$, a real-valued observable $X$, taking values in $\mathcal{X}$, has density function $p_{i}(\cdot)$. Define the Type I error $\alpha$ and the Type II error $\beta$ of a test $\phi: \mathcal{X} \rightarrow[0,1]$ of the null hypothesis $H_{0}$ against the alternative hypothesis $H_{1}$. What are the size and power of the test in terms of $\alpha$ and $\beta$ ?

Show that, for $0<c<\infty, \phi$ minimises $c \alpha+\beta$ among all possible tests if and only if it satisfies

$$\begin{aligned}
&p_{1}(x)>c p_{0}(x) \Rightarrow \phi(x)=1 \\
&p_{1}(x)<c p_{0}(x) \Rightarrow \phi(x)=0
\end{aligned}$$

What does this imply about the admissibility of such a test?

Given the value $\theta$ of a parameter variable $\Theta \in[0,1)$, the observable $X$ has density function

$$p(x \mid \theta)=\frac{2(x-\theta)}{(1-\theta)^{2}} \quad(\theta \leqslant x \leqslant 1)$$

For fixed $\theta \in(0,1)$, describe all the likelihood ratio tests of $H_{0}: \Theta=0$ against $H_{\theta}: \Theta=\theta$.

For fixed $k \in(0,1)$, let $\phi_{k}$ be the test that rejects $H_{0}$ if and only if $X \geqslant k$. Is $\phi_{k}$ admissible as a test of $H_{0}$ against $H_{\theta}$ for every $\theta \in(0,1)$ ? Is it uniformly most powerful for its size for testing $H_{0}$ against the composite hypothesis $H_{1}: \Theta \in(0,1)$ ? Is it admissible as a test of $H_{0}$ against $H_{1}$ ?