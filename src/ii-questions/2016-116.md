---
course: Principles of Statistics
course_year: II
question_number: 116
tags:
- II
- '2016'
- Principles of Statistics
title: 'Paper 1, Section II, $\mathbf{2 7 J}$ '
year: 2016
---



Derive the maximum likelihood estimator $\hat{\theta}_{n}$ based on independent observations $X_{1}, \ldots, X_{n}$ that are identically distributed as $N(\theta, 1)$, where the unknown parameter $\theta$ lies in the parameter space $\Theta=\mathbb{R}$. Find the limiting distribution of $\sqrt{n}\left(\widehat{\theta}_{n}-\theta\right)$ as $n \rightarrow \infty$.

Now define

$$\begin{array}{rll}
\tilde{\theta}_{n} & =\widehat{\theta}_{n} & \text { whenever }\left|\widehat{\theta}_{n}\right|>n^{-1 / 4}, \\
& =0 & \text { otherwise, }
\end{array}$$

$$\begin{aligned}
& =0 \text { otherwise, }
\end{aligned}$$

and find the limiting distribution of $\sqrt{n}\left(\tilde{\theta}_{n}-\theta\right)$ as $n \rightarrow \infty$.

Calculate

$$\lim _{n \rightarrow \infty} \sup _{\theta \in \Theta} n E_{\theta}\left(T_{n}-\theta\right)^{2}$$

for the choices $T_{n}=\widehat{\theta}_{n}$ and $T_{n}=\widetilde{\theta}_{n}$. Based on the above findings, which estimator $T_{n}$ of $\theta$ would you prefer? Explain your answer.

[Throughout, you may use standard facts of stochastic convergence, such as the central limit theorem, provided they are clearly stated.]