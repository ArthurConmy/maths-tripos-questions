---
course: Principles of Statistics
course_year: II
question_number: 119
tags:
- II
- '2020'
- Principles of Statistics
title: 'Paper 4 , Section II, J '
year: 2020
---



Consider $X_{1}, \ldots, X_{n}$ drawn from a statistical model $\{f(\cdot, \theta): \theta \in \Theta\}, \Theta=\mathbb{R}^{p}$, with non-singular Fisher information matrix $I(\theta)$. For $\theta_{0} \in \Theta, h \in \mathbb{R}^{p}$, define likelihood ratios

$$Z_{n}(h)=\log \frac{\prod_{i=1}^{n} f\left(X_{i}, \theta_{0}+h / \sqrt{n}\right)}{\prod_{i=1}^{n} f\left(X_{i}, \theta_{0}\right)}, \quad X_{i} \sim^{i . i . d .} f\left(\cdot, \theta_{0}\right)$$

Next consider the probability density functions $\left(p_{h}: h \in \mathbb{R}^{p}\right)$ of normal distributions $N\left(h, I\left(\theta_{0}\right)^{-1}\right)$ with corresponding likelihood ratios given by

$$Z(h)=\log \frac{p_{h}(X)}{p_{0}(X)}, \quad X \sim p_{0} .$$

Show that for every fixed $h \in \mathbb{R}^{p}$, the random variables $Z_{n}(h)$ converge in distribution as $n \rightarrow \infty$ to $Z(h) .$

[You may assume suitable regularity conditions of the model $\{f(\cdot, \theta): \theta \in \Theta\}$ without specification, and results on uniform laws of large numbers from lectures can be used without proof.]