---
course: Mathematical Biology
course_year: II
question_number: 35
tags:
- II
- '2005'
- Mathematical Biology
title: '4.I.6E '
year: 2005
---


The output of a linear perceptron is given by $y=\mathbf{w} \cdot \mathbf{x}$, where $\mathbf{w}$ is a vector of weights connecting a fluctuating input vector $x$ to an output unit. The weights are given random initial values and are then updated according to a learning rule that has a time-constant $\tau$ much greater than the fluctuation timescale of the inputs.

(a) Find the behaviour of $|\mathbf{w}|$ for each of the following two rules
(i) $\tau \frac{d \mathbf{w}}{d t}=y \mathbf{x}$
(ii) $\tau \frac{d \mathbf{w}}{d t}=y \mathbf{x}-\alpha y^{2} \mathbf{w}|\mathbf{w}|^{2}$, where $\alpha$ is a positive constant.

(b) Consider a third learning rule

$$\text { (iii) } \tau \frac{d \mathbf{w}}{d t}=y \mathbf{x}-\mathbf{w}|\mathbf{w}|^{2} \text {. }$$

Show that in a steady state the vector of weights satisfies the eigenvalue equation

$$\mathbf{C w}=\lambda \mathbf{w}$$

where the matrix $\mathbf{C}$ and eigenvalue $\lambda$ should be identified.

(c) Comment briefly on the biological implications of the three rules.