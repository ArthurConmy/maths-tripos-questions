---
course: Principles of Statistics
course_year: II
question_number: 118
tags:
- II
- '2018'
- Principles of Statistics
title: 'Paper 2, Section II, $28 K$ '
year: 2018
---



We consider the model $\left\{\mathcal{N}\left(\theta, I_{p}\right), \theta \in \mathbb{R}^{p}\right\}$ of a Gaussian distribution in dimension $p \geqslant 3$, with unknown mean $\theta$ and known identity covariance matrix $I_{p}$. We estimate $\theta$ based on one observation $X \sim \mathcal{N}\left(\theta, I_{p}\right)$, under the loss function

$$\ell(\theta, \delta)=\|\theta-\delta\|_{2}^{2}$$

(a) Define the risk of an estimator $\hat{\theta}$. Compute the maximum likelihood estimator $\hat{\theta}_{M L E}$ of $\theta$ and its risk for any $\theta \in \mathbb{R}^{p}$.

(b) Define what an admissible estimator is. Is $\hat{\theta}_{M L E}$ admissible?

(c) For any $c>0$, let $\pi_{c}(\theta)$ be the prior $\mathcal{N}\left(0, c^{2} I_{p}\right)$. Find a Bayes optimal estimator $\hat{\theta}_{c}$ under this prior with the quadratic loss, and compute its Bayes risk.

(d) Show that $\hat{\theta}_{M L E}$ is minimax.

[You may use results from the course provided that you state them clearly.]