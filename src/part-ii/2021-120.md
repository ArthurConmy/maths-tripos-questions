---
course: Principles of Statistics
course_year: II
question_number: 120
tags:
- II
- '2021'
- Principles of Statistics
title: 'Paper 4, Section II, J '
year: 2021
---



Suppose that $X \mid \theta \sim \operatorname{Poisson}(\theta), \theta>0$, and suppose the prior $\pi$ on $\theta$ is a gamma distribution with parameters $\alpha>0$ and $\beta>0$. [Recall that $\pi$ has probability density function

$$f(z)=\frac{\beta^{\alpha}}{\Gamma(\alpha)} z^{\alpha-1} e^{-\beta z}, \quad z>0$$

and that its mean and variance are $\alpha / \beta$ and $\alpha / \beta^{2}$, respectively. ]

(a) Find the $\pi$-Bayes estimator for $\theta$ for the quadratic loss, and derive its quadratic risk function.

(b) Suppose we wish to estimate $\mu=e^{-\theta}=\mathbb{P}_{\theta}(X=0)$. Find the $\pi$-Bayes estimator for $\mu$ for the quadratic loss, and derive its quadratic risk function. [Hint: The moment generating function of a Poisson $(\theta)$ distribution is $M(t)=\exp \left(\theta\left(e^{t}-1\right)\right)$ for $t \in \mathbb{R}$, and that of a Gamma $(\alpha, \beta)$ distribution is $M(t)=(1-t / \beta)^{-\alpha}$ for $t<\beta$.]

(c) State a sufficient condition for an admissible estimator to be minimax, and give a proof of this fact.

(d) For each of the estimators in parts (a) and (b), is it possible to deduce using the condition in (c) that the estimator is minimax for some value of $\alpha$ and $\beta$ ? Justify your answer.