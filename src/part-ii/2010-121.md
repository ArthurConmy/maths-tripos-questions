---
course: Principles of Statistics
course_year: II
question_number: 121
tags:
- II
- '2010'
- Principles of Statistics
title: 'Paper 4, Section II, $\mathbf{2 7 J}$ '
year: 2010
---



Define completeness and bounded completeness of a statistic $T$ in a statistical experiment.

Random variables $X_{1}, X_{2}, X_{3}$ are generated as $X_{i}=\Theta^{1 / 2} Z+(1-\Theta)^{1 / 2} Y_{i}$, where $Z, Y_{1}, Y_{2}, Y_{3}$ are independently standard normal $\mathcal{N}(0,1)$, and the parameter $\Theta$ takes values in $(0,1)$. What is the joint distribution of $\left(X_{1}, X_{2}, X_{3}\right)$ when $\Theta=\theta$ ? Write down its density function, and show that a minimal sufficient statistic for $\Theta$ based on $\left(X_{1}, X_{2}, X_{3}\right)$ is $T=\left(T_{1}, T_{2}\right):=\left(\sum_{i=1}^{3} X_{i}^{2},\left(\sum_{i=1}^{3} X_{i}\right)^{2}\right)$.

[Hint: You may use that if $I$ is the $n \times n$ identity matrix and $J$ is the $n \times n$ matrix all of whose entries are 1 , then $a I+b J$ has determinant $a^{n-1}(a+n b)$, and inverse $c I+d J$ with $c=1 / a, d=-b /(a(a+n b))$.]

What is $\mathbb{E}_{\theta}\left(T_{1}\right) ?$ Is $T$ complete for $\Theta ?$

Let $S:=\operatorname{Prob}\left(X_{1}^{2} \leqslant 1 \mid T\right)$. Show that $\mathbb{E}_{\theta}(S)$ is a positive constant $c$ which does not depend on $\theta$, but that $S$ is not identically equal to $c$. Is $T$ boundedly complete for $\Theta$ ?