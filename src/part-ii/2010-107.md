---
course: Optimization and Control
course_year: II
question_number: 107
tags:
- II
- '2010'
- Optimization and Control
title: 'Paper 2, Section II, J '
year: 2010
---



(a) Suppose that

$$\left(\begin{array}{l}
X \\
Y
\end{array}\right) \sim N\left(\left(\begin{array}{l}
\mu_{X} \\
\mu_{Y}
\end{array}\right),\left(\begin{array}{ll}
V_{X X} & V_{X Y} \\
V_{Y X} & V_{Y Y}
\end{array}\right)\right)$$

Prove that conditional on $Y=y$, the distribution of $X$ is again multivariate normal, with mean $\mu_{X}+V_{X Y} V_{Y Y}^{-1}\left(y-\mu_{Y}\right)$ and covariance $V_{X X}-V_{X Y} V_{Y Y}^{-1} V_{Y X}$.

(b) The $\mathbb{R}^{d}$-valued process $X$ evolves in discrete time according to the dynamics

$$X_{t+1}=A X_{t}+\varepsilon_{t+1}$$

where $A$ is a constant $d \times d$ matrix, and $\varepsilon_{t}$ are independent, with common $N\left(0, \Sigma_{\varepsilon}\right)$ distribution. The process $X$ is not observed directly; instead, all that is seen is the process $Y$ defined as

$$Y_{t}=C X_{t}+\eta_{t},$$

where $\eta_{t}$ are independent of each other and of the $\varepsilon_{t}$, with common $N\left(0, \Sigma_{\eta}\right)$ distribution.

If the observer has the prior distribution $X_{0} \sim N\left(\hat{X}_{0}, V_{0}\right)$ for $X_{0}$, prove that at all later times the distribution of $X_{t}$ conditional on $\mathcal{Y}_{t} \equiv\left(Y_{1}, \ldots, Y_{t}\right)$ is again normally distributed, with mean $\hat{X}_{t}$ and covariance $V_{t}$ which evolve as

$$\begin{aligned}
\hat{X}_{t+1} &=A \hat{X}_{t}+M_{t} C^{T}\left(\Sigma_{\eta}+C M_{t} C^{T}\right)^{-1}\left(Y_{t+1}-C A \hat{X}_{t}\right) \\
V_{t+1} &=M_{t}-M_{t} C^{T}\left(\Sigma_{\eta}+C M_{t} C^{T}\right)^{-1} C M_{t}
\end{aligned}$$

where

$$M_{t}=A V_{t} A^{T}+\Sigma_{\varepsilon}$$

(c) In the special case where both $X$ and $Y$ are one-dimensional, and $A=C=1$, $\Sigma_{\varepsilon}=0$, find the form of the updating recursion. Show in particular that

$$\frac{1}{V_{t+1}}=\frac{1}{V_{t}}+\frac{1}{\Sigma_{\eta}}$$

and that

$$\frac{\hat{X}_{t+1}}{V_{t+1}}=\frac{\hat{X}_{t}}{V_{t}}+\frac{Y_{t+1}}{\Sigma_{\eta}}$$

Hence deduce that, with probability one,

$$\lim _{t \rightarrow \infty} \hat{X}_{t}=\lim _{t \rightarrow \infty} t^{-1} \sum_{j=1}^{t} Y_{j}$$