---
course: Coding \& Cryptography
course_year: II
question_number: 39
tags:
- II
- '2017'
- Coding \& Cryptography
title: 'Paper 2, Section II, G '
year: 2017
---



Define the entropy, $H(X)$, of a random variable $X$. State and prove Gibbs' inequality.

Hence, or otherwise, show that $H\left(p_{1}, p_{2}, p_{3}\right) \leqslant H\left(p_{1}, 1-p_{1}\right)+\left(1-p_{1}\right)$ and determine when equality occurs.

Show that the Discrete Memoryless Channel with channel matrix

$$\left(\begin{array}{ccc}
1-\alpha-\beta & \alpha & \beta \\
\alpha & 1-\alpha-\beta & \beta
\end{array}\right)$$

has capacity $C=(1-\beta)(1-\log (1-\beta))+(1-\alpha-\beta) \log (1-\alpha-\beta)+\alpha \log \alpha$.