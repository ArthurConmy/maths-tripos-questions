---
course: Principles of Statistics
course_year: II
question_number: 120
tags:
- II
- '2009'
- Principles of Statistics
title: 'Paper 1, Section II, I '
year: 2009
---



(i) Let $X_{1}, \ldots, X_{n}$ be independent and identically distributed random variables, having the exponential distribution $\mathcal{E}(\lambda)$ with density $p(x \mid \lambda)=\lambda \exp (-\lambda x)$ for $x, \lambda>0$. Show that $T_{n}=\sum_{i=1}^{n} X_{i}$ is minimal sufficient and complete for $\lambda$.

[You may assume uniqueness of Laplace transforms.]

(ii) For given $x>0$, it is desired to estimate the quantity $\phi=\operatorname{Prob}\left(X_{1}>x \mid \lambda\right)$. Compute the Fisher information for $\phi$.

(iii) State the Lehmann-Scheffé theorem. Show that the estimator $\tilde{\phi}_{n}$ of $\phi$ defined by

$$\tilde{\phi}_{n}= \begin{cases}0, & \text { if } T_{n}<x, \\ \left(1-\frac{x}{T_{n}}\right)^{n-1}, & \text { if } T_{n} \geqslant x\end{cases}$$

is the minimum variance unbiased estimator of $\phi$ based on $\left(X_{1}, \ldots, X_{n}\right)$. Without doing any computations, state whether or not the variance of $\tilde{\phi}_{n}$ achieves the Cramér-Rao lower bound, justifying your answer briefly.

Let $k \leqslant n$. Show that $\mathbb{E}\left(\tilde{\phi}_{k} \mid T_{n}, \lambda\right)=\tilde{\phi}_{n}$.