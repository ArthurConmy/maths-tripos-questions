---
course: Principles of Statistics
course_year: II
question_number: 119
tags:
- II
- '2017'
- Principles of Statistics
title: 'Paper 1, Section II, $28 \mathrm{~K}$ '
year: 2017
---



For a positive integer $n$, we want to estimate the parameter $p$ in the binomial statistical model $\{\operatorname{Bin}(n, p), p \in[0,1]\}$, based on an observation $X \sim \operatorname{Bin}(n, p)$.

(a) Compute the maximum likelihood estimator for $p$. Show that the posterior distribution for $p$ under a uniform prior on $[0,1]$ is $\operatorname{Beta}(a, b)$, and specify $a$ and $b$. [The p.d.f. of $\operatorname{Beta}(a, b)$ is given by

$$\left.f_{a, b}(p)=\frac{(a+b-1) !}{(a-1) !(b-1) !} p^{a-1}(1-p)^{b-1} .\right]$$

(b) (i) For a risk function $L$, define the risk of an estimator $\hat{p}$ of $p$, and the Bayes risk under a prior $\pi$ for $p$.

(ii) Under the loss function

$$L(\hat{p}, p)=\frac{(\hat{p}-p)^{2}}{p(1-p)}$$

find a Bayes optimal estimator for the uniform prior. Give its risk as a function of $p$.

(iii) Give a minimax optimal estimator for the loss function $L$ given above. Justify your answer.