---
course: Principles of Statistics
course_year: II
question_number: 105
tags:
- II
- '2005'
- Principles of Statistics
title: '3.II.26I '
year: 2005
---


In the context of decision theory, explain the meaning of the following italicized terms: loss function, decision rule, the risk of a decision rule, a Bayes rule with respect to prior $\pi$, and an admissible rule. Explain how a Bayes rule with respect to a prior $\pi$ can be constructed.

Suppose that $X_{1}, \ldots, X_{n}$ are independent with common $N(0, v)$ distribution, where $v>0$ is supposed to have a prior density $f_{0}$. In a decision-theoretic approach to estimating $v$, we take a quadratic loss: $L(v, a)=(v-a)^{2}$. Write $X=\left(X_{1}, \ldots, X_{n}\right)$ and $|X|=\left(X_{1}^{2}+\ldots+X_{n}^{2}\right)^{1 / 2}$.

By considering decision rules (estimators) of the form $\hat{v}(X)=\alpha|X|^{2}$, prove that if $\alpha \neq 1 /(n+2)$ then the estimator $\hat{v}(X)=\alpha|X|^{2}$ is not Bayes, for any choice of prior $f_{0}$.

By considering decision rules of the form $\hat{v}(X)=\alpha|X|^{2}+\beta$, prove that if $\alpha \neq 1 / n$ then the estimator $\hat{v}(X)=\alpha|X|^{2}$ is not Bayes, for any choice of prior $f_{0}$.

[You may use without proof the fact that, if $Z$ has a $N(0,1)$ distribution, then $E Z^{4}=3$.]