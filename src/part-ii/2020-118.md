---
course: Principles of Statistics
course_year: II
question_number: 118
tags:
- II
- '2020'
- Principles of Statistics
title: 'Paper 3, Section II, J '
year: 2020
---



Let $\Theta=\mathbb{R}^{p}$, let $\mu>0$ be a probability density function on $\Theta$ and suppose we are given a further auxiliary conditional probability density function $q(\cdot \mid t)>0, t \in \Theta$, on $\Theta$ from which we can generate random draws. Consider a sequence of random variables $\left\{\vartheta_{m}: m \in \mathbb{N}\right\}$ generated as follows:

- For $m \in \mathbb{N}$ and given $\vartheta_{m}$, generate a new draw $s_{m} \sim q\left(\cdot \mid \vartheta_{m}\right)$.

- Define

$$\vartheta_{m+1}= \begin{cases}s_{m}, & \text { with probability } \rho\left(\vartheta_{m}, s_{m}\right) \\ \vartheta_{m}, & \text { with probability } 1-\rho\left(\vartheta_{m}, s_{m}\right)\end{cases}$$

where $\rho(t, s)=\min \left\{\frac{\mu(s)}{\mu(t)} \frac{q(t \mid s)}{q(s \mid t)}, 1\right\}$.

(i) Show that the Markov chain $\left(\vartheta_{m}\right)$ has invariant measure $\mu$, that is, show that for all (measurable) subsets $B \subset \Theta$ and all $m \in \mathbb{N}$ we have

$$\int_{\Theta} \operatorname{Pr}\left(\vartheta_{m+1} \in B \mid \vartheta_{m}=t\right) \mu(t) d t=\int_{B} \mu(\theta) d \theta$$

(ii) Now suppose that $\mu$ is the posterior probability density function arising in a statistical model $\{f(\cdot, \theta): \theta \in \Theta\}$ with observations $x$ and a $N\left(0, I_{p}\right)$ prior distribution on $\theta$. Derive a family $\{q(\cdot \mid t): t \in \Theta\}$ such that in the above algorithm the acceptance probability $\rho(t, s)$ is a function of the likelihood ratio $f(x, s) / f(x, t)$, and for which the probability density function $q(\cdot \mid t)$ has covariance matrix $2 \delta I_{p}$ for all $t \in \Theta$.