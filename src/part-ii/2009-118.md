---
course: Principles of Statistics
course_year: II
question_number: 118
tags:
- II
- '2009'
- Principles of Statistics
title: 'Paper 3, Section II, I '
year: 2009
---



What is meant by an equaliser decision rule? What is meant by an extended Bayes rule? Show that a decision rule that is both an equaliser rule and extended Bayes is minimax.

Let $X_{1}, \ldots, X_{n}$ be independent and identically distributed random variables with the normal distribution $\mathcal{N}\left(\theta, h^{-1}\right)$, and let $k>0$. It is desired to estimate $\theta$ with loss function $L(\theta, a)=1-\exp \left\{-\frac{1}{2} k(a-\theta)^{2}\right\}$.

Suppose the prior distribution is $\theta \sim \mathcal{N}\left(m_{0}, h_{0}^{-1}\right)$. Find the Bayes act and the Bayes loss posterior to observing $X_{1}=x_{1}, \ldots, X_{n}=x_{n}$. What is the Bayes risk of the Bayes rule with respect to this prior distribution?

Show that the rule that estimates $\theta$ by $\bar{X}=n^{-1} \sum_{i=1}^{n} X_{i}$ is minimax.